{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp_diabetes.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaximoDouglas/deep_learning/blob/master/code/colab/mlp_diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "co4MgreoOh9A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Upload the .csv files\n",
        "pima-indians-diabetes.csv\n",
        "\n",
        "pima-indians-diabetes_labeled.csv"
      ]
    },
    {
      "metadata": {
        "id": "V_j8CUcDIACp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VATlX4dQO2x8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Code - direct from the book"
      ]
    },
    {
      "metadata": {
        "id": "pVzbmcfbPAIR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import numpy\n",
        "\n",
        "# fix random seed for reproducibility - it allows that no matter if we execute \n",
        "# the code more than one time, the random values have to be the same\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
        "model.add(Dense(8, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "\n",
        "# Compile model \n",
        "# binary_crossentropy = logarithmic loss\n",
        "# adam = gradient descent algorithm\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10)\n",
        "\n",
        "# Evaluating model with the training data\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iebJtCwjFUah",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Code - Altered by Maximo, D.H.\n",
        "\n",
        "This code is working with manually splited training and validating data"
      ]
    },
    {
      "metadata": {
        "id": "5cKFEZMPFTIE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import numpy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# fix random seed for reproducibility - it allows that no matter if we execute \n",
        "# the code more than one time, the random values have to be the same\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load pima indians dataset\n",
        "df = pd.read_csv(\"pima-indians-diabetes_labeled.csv\")\n",
        "\n",
        "# split into input (X) and output (y) variables\n",
        "X = df.drop(['class'], 1, inplace=False)\n",
        "y = df['class']\n",
        "\n",
        "# split the dataset into training data and validating data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
        "model.add(Dense(8, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "\n",
        "# Compile model \n",
        "# binary_crossentropy = logarithmic loss\n",
        "# adam = gradient descent algorithm\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=10)\n",
        "\n",
        "# Evaluating model with the training data\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tsGPu0rUPHMu"
      },
      "cell_type": "markdown",
      "source": [
        "# Code - Altered by Maximo, D.H.\n",
        "\n",
        "This code is working with automatically splited training and validating data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yC_k4mZ0PHMy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import numpy\n",
        "import pandas as pd\n",
        "\n",
        "# fix random seed for reproducibility - it allows that no matter if we execute \n",
        "# the code more than one time, the random values have to be the same\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load pima indians dataset\n",
        "df = pd.read_csv(\"pima-indians-diabetes_labeled.csv\")\n",
        "\n",
        "# split into input (X) and output (y) variables\n",
        "X = df.drop(['class'], 1, inplace=False)\n",
        "y = df['class']\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
        "model.add(Dense(8, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "\n",
        "# Compile model \n",
        "# binary_crossentropy = logarithmic loss\n",
        "# adam = gradient descent algorithm\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y, validation_split=0.2, epochs=150, batch_size=10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}