{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp_diabetes.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaximoDouglas/deep-learning-with-python-brownlee/blob/master/code/colab/part_three/mlp_diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "co4MgreoOh9A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get file"
      ]
    },
    {
      "metadata": {
        "id": "V_j8CUcDIACp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget \"http://ftp.ics.uci.edu/pub/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\" -O pima-indians-diabetes.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VATlX4dQO2x8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Code - First example direct from the book"
      ]
    },
    {
      "metadata": {
        "id": "pVzbmcfbPAIR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy\n",
        "\n",
        "# fix random seed for reproducibility - it allows that no matter if we execute \n",
        "# the code more than one time, the random values have to be the same\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
        "model.add(Dense(8, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "\n",
        "# Compile model \n",
        "# binary_crossentropy = logarithmic loss\n",
        "# adam = gradient descent algorithm\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
        "\n",
        "# Evaluating model with the training data\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SMNaNj-EwXnd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Code - Manual k-Fold Cross Validation (adapted)\n"
      ]
    },
    {
      "metadata": {
        "id": "qrYV6e17wdPK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MLP for Pima Indians Dataset with 10-fold cross validation\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# define 10-fold cross validation test harness\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "cvscores = []\n",
        "\n",
        "for (train, test) in kfold.split(X, Y):\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
        "  model.add(Dense(8, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
        "  model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "  \n",
        "  # Compile model\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  # Fit the model\n",
        "  history = model.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0)\n",
        "  \n",
        "  # evaluate the model\n",
        "  scores = model.evaluate(X[test], Y[test], verbose=0)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  cvscores.append(scores[1] * 100)\n",
        "  \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jIovlMHT7hII",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Code - Keras and Scikit-learn (adapted)"
      ]
    },
    {
      "metadata": {
        "id": "pXdZIeYN7xU2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MLP for Pima Indians Dataset with 10-fold cross validation via sklearn\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
        "  model.add(Dense(8, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
        "  model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\"))\n",
        "  \n",
        "  # Compile model\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10)\n",
        "\n",
        "# evaluate using 10-fold cross validation\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(model, X, y, cv=kfold)\n",
        "print(\"Acc: %.2f%%\"%((results.mean())*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6swN0pmjvNM_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Code - Grid Search (adapted)"
      ]
    },
    {
      "metadata": {
        "id": "Ss9z5qTBvMMV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MLP for Pima Indians Dataset with grid search via sklearn\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(optimizer=\"rmsprop\", init=\"glorot_uniform\"):\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=init))\n",
        "  model.add(Dense(8, activation=\"relu\", kernel_initializer=init))\n",
        "  model.add(Dense(1, activation=\"sigmoid\", kernel_initializer=init))\n",
        "\n",
        "  # Compile model\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "\n",
        "# grid search epochs, batch size and optimizer\n",
        "optimizers = ['rmsprop', 'adam']\n",
        "init = ['glorot_uniform', 'normal', 'uniform']\n",
        "eps = numpy.array([50, 100, 150])\n",
        "batches = numpy.array([5, 10, 20])\n",
        "\n",
        "param_grid = dict(optimizer=optimizers, epochs=eps, batch_size=batches, init=init)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result = grid.fit(X, y)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "#The way the book print the summarization of other params combinations is \n",
        "# deprecate. So, in my code I had to adapt the new grid_result return to print\n",
        "# like in the book. The altered code is in \n",
        "# \"Code - Grid Search (alterede by Maximo, D.H.)\" jupyter section, or, in \n",
        "# github: /deep_learning/code/local_env/009_mlp_diabetes_GSearch-maximo.py"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}