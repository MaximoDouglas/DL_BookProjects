{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bc_sonar.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaximoDouglas/deep-learning-with-python-brownlee/blob/master/code/colab/part_three/bc_sonar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tMpEtM9Irwxy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get the data file"
      ]
    },
    {
      "metadata": {
        "id": "i7z63JDcr1tr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\" -O sonar.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DGOle30StkJr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Code - direct from the book (adapted)\n",
        "\n",
        "Accuracy: 80.78%\n",
        "\n",
        "Standard deviation: 5.35%"
      ]
    },
    {
      "metadata": {
        "id": "wXVa1_UntoGT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Binary Classification with Sonar Dataset: Baseline\n",
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# ----- Begin data preprocessing\n",
        "\n",
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"sonar.data\", header=None)\n",
        "dataset = dataframe.values\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:60].astype(float)\n",
        "Y = dataset[:,60]\n",
        "\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "\n",
        "# ----- End data preprocessing\n",
        "\n",
        "# baseline model\n",
        "def create_baseline():\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        "  # Compile model\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# evaluate model with standardized dataset\n",
        "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5)\n",
        "skfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(estimator, X, encoded_Y, cv=skfold)\n",
        "\n",
        "# Summarize\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9KbHuq3AC02u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Code - With StandarScaler and Pipeline (adapted)\n",
        "Accuracy: 84.63% \n",
        "\n",
        "Standard deviation: 7.65%"
      ]
    },
    {
      "metadata": {
        "id": "dlqmud4nC-wf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Binary Classification with Sonar Dataset: Standardized\n",
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"sonar.data\", header=None)\n",
        "dataset = dataframe.values\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:60].astype(float)\n",
        "Y = dataset[:,60]\n",
        "\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "\n",
        "# baseline model\n",
        "def create_baseline():\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(60, input_dim=60, kernel_initializer='normal', activation='relu'))\n",
        "  model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        "  # Compile model\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# evaluate baseline model with standardized dataset\n",
        "numpy.random.seed(seed)\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5)))\n",
        "pipeline = Pipeline(estimators)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(pipeline, X, encoded_Y, cv=skfold)\n",
        "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "f7LNQK9W80ce"
      },
      "cell_type": "markdown",
      "source": [
        "# Code - With smaller network (adapted)\n",
        "Accuracy: 84.56%\n",
        "\n",
        "Standard deviation:  6.86%"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mJfhQ-zn80cj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Binary Classification with Sonar Dataset: Standardized Smaller\n",
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# Begin data preprocessing\n",
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"sonar.data\", header=None)\n",
        "dataset = dataframe.values\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:60].astype(float)\n",
        "Y = dataset[:,60]\n",
        "\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "# End data preprocessing\n",
        "\n",
        "# smaller model\n",
        "def create_smaller():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(30, input_dim=60, kernel_initializer=\"normal\", activation=\"relu\"))\n",
        "    model.add(Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\"))\n",
        "    # Compile model\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append((\"standardize\", StandardScaler()))\n",
        "estimators.append((\"mlp\", KerasClassifier(build_fn=create_smaller, epochs=100, batch_size=5)))\n",
        "pipeline = Pipeline(estimators)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(pipeline, X, encoded_Y, cv=skfold)\n",
        "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "W7nL4lGU94KA"
      },
      "cell_type": "markdown",
      "source": [
        "# Code - With larger network (adapted)\n",
        "Accuracy: 85.09% \n",
        "\n",
        "Standard deviation: 9.43%"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kl4k1wOF94KD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Binary Classification with Sonar Dataset: Standardized Larger\n",
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"sonar.data\", header=None)\n",
        "dataset = dataframe.values\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:60].astype(float)\n",
        "Y = dataset[:,60]\n",
        "\n",
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "\n",
        "# larger model\n",
        "def create_larger():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(60, input_dim=60, kernel_initializer=\"normal\", activation=\"relu\"))\n",
        "    model.add(Dense(30, kernel_initializer=\"normal\", activation=\"relu\"))\n",
        "    model.add(Dense(1, kernel_initializer=\"normal\", activation=\"sigmoid\"))\n",
        "    # Compile model\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "numpy.random.seed(seed)\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5)))\n",
        "pipeline = Pipeline(estimators)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "results = cross_val_score(pipeline, X, encoded_Y, cv=skfold)\n",
        "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}