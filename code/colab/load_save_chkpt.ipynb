{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_save_chkpt.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaximoDouglas/deep_learning/blob/master/code/colab/load_save_chkpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "co4MgreoOh9A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Upload the .csv files\n",
        "\n",
        "pima-indians-diabetes_labeled.csv"
      ]
    },
    {
      "metadata": {
        "id": "V_j8CUcDIACp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VATlX4dQO2x8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Code - Save and load models - JSON - adapted"
      ]
    },
    {
      "metadata": {
        "id": "pVzbmcfbPAIR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import model_from_json\n",
        "import numpy\n",
        "import os\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# Begin data preprocessing\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "# End data preprocessing\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
        "model.add(Dense(8, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
        "model.add(Dense(1, kernel_initializer=\"uniform\", activation=\"sigmoid\"))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"Pre-loaded | %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# Saving model and weights\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"001.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"001.h5\")\n",
        "# End saving model and weights\n",
        "\n",
        "# Loading model and weights\n",
        "# load model\n",
        "json_file = open('001.json','r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"001.h5\")\n",
        "# End loading model and weights\n",
        "\n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X, Y)\n",
        "print(\"Loaded | %s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GxW3NlO8G9Jh"
      },
      "cell_type": "markdown",
      "source": [
        "# Code - Save and load models - YAML - adapted"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Au0yziN2G9Jl",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import model_from_yaml\n",
        "import numpy\n",
        "import os\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "# Begin data preprocessing\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "# create model\n",
        "# End data preprocessing\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
        "model.add(Dense(8, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
        "model.add(Dense(1, kernel_initializer=\"uniform\", activation=\"sigmoid\"))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"Pre-loaded | %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# Saving model and weights\n",
        "# serialize model to YAML\n",
        "model_yaml = model.to_yaml()\n",
        "with open(\"002.yaml\", \"w\") as yaml_file:\n",
        "    yaml_file.write(model_yaml)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"002.h5\")\n",
        "# End saving model and weights\n",
        "\n",
        "# Loading model and weights\n",
        "# load model\n",
        "yaml_file = open('002.yaml', 'r')\n",
        "loaded_model_yaml = yaml_file.read()\n",
        "yaml_file.close()\n",
        "loaded_model = model_from_yaml(loaded_model_yaml)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"002.h5\")\n",
        "# End loading model and weights\n",
        "\n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X, Y)\n",
        "print(\"Loaded | %s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LXcbCINHpVY2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Code - Saving checkpoints\n",
        "Save weights of training improvements"
      ]
    },
    {
      "metadata": {
        "id": "WEB6nqMbq1ce",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir saved_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PKVGo4R3pgxL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5154
        },
        "outputId": "50180cb6-43c0-4973-f527-c034d0e4a416"
      },
      "cell_type": "code",
      "source": [
        "# Checkpoint the weights when validation accuracy improves\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
        "model.add(Dense(8, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
        "model.add(Dense(1, kernel_initializer=\"uniform\", activation=\"sigmoid\"))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "# checkpoint\n",
        "filepath= \"saved_weights/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor=\"val_acc\", verbose=1, save_best_only=True, mode=\"max\")\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, callbacks=callbacks_list, verbose=0)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.67323, saving model to saved_weights/weights-improvement-01-0.67.hdf5\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.67323\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.67323\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.67323 to 0.69291, saving model to saved_weights/weights-improvement-04-0.69.hdf5\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.69291\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.69291\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.69291\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.69291\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.69291 to 0.69291, saving model to saved_weights/weights-improvement-09-0.69.hdf5\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.69291\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.69291\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.69291\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.69291\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.69291 to 0.69685, saving model to saved_weights/weights-improvement-14-0.70.hdf5\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.69685\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.69685\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.69685\n",
            "\n",
            "Epoch 00018: val_acc improved from 0.69685 to 0.70079, saving model to saved_weights/weights-improvement-18-0.70.hdf5\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.70079 to 0.70472, saving model to saved_weights/weights-improvement-19-0.70.hdf5\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.70472\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.70472\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.70472\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.70472\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.70472\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.70472 to 0.70866, saving model to saved_weights/weights-improvement-25-0.71.hdf5\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.70866 to 0.71260, saving model to saved_weights/weights-improvement-26-0.71.hdf5\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.71260\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.71260\n",
            "\n",
            "Epoch 00029: val_acc improved from 0.71260 to 0.72047, saving model to saved_weights/weights-improvement-29-0.72.hdf5\n",
            "\n",
            "Epoch 00030: val_acc improved from 0.72047 to 0.72047, saving model to saved_weights/weights-improvement-30-0.72.hdf5\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.72047 to 0.72835, saving model to saved_weights/weights-improvement-31-0.73.hdf5\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.72835\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.72835\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.72835\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.72835\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.72835\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.72835\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.72835\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.72835\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.72835\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.72835\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.72835\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.72835\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.72835\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.72835\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.72835\n",
            "\n",
            "Epoch 00047: val_acc improved from 0.72835 to 0.73228, saving model to saved_weights/weights-improvement-47-0.73.hdf5\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.73228\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.73228\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.73228\n",
            "\n",
            "Epoch 00051: val_acc improved from 0.73228 to 0.74409, saving model to saved_weights/weights-improvement-51-0.74.hdf5\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.74409\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.74409\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.74409\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.74409\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.74409\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.74409\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.74409\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.74409\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.74409\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.74409\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.74409\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.74409\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.74409\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.74409\n",
            "\n",
            "Epoch 00066: val_acc improved from 0.74409 to 0.76772, saving model to saved_weights/weights-improvement-66-0.77.hdf5\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00074: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00088: val_acc improved from 0.76772 to 0.76772, saving model to saved_weights/weights-improvement-88-0.77.hdf5\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00094: val_acc improved from 0.76772 to 0.76772, saving model to saved_weights/weights-improvement-94-0.77.hdf5\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.76772\n",
            "\n",
            "Epoch 00099: val_acc improved from 0.76772 to 0.77165, saving model to saved_weights/weights-improvement-99-0.77.hdf5\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.77165\n",
            "\n",
            "Epoch 00101: val_acc did not improve from 0.77165\n",
            "\n",
            "Epoch 00102: val_acc did not improve from 0.77165\n",
            "\n",
            "Epoch 00103: val_acc did not improve from 0.77165\n",
            "\n",
            "Epoch 00104: val_acc did not improve from 0.77165\n",
            "\n",
            "Epoch 00105: val_acc did not improve from 0.77165\n",
            "\n",
            "Epoch 00106: val_acc did not improve from 0.77165\n",
            "\n",
            "Epoch 00107: val_acc did not improve from 0.77165\n",
            "\n",
            "Epoch 00108: val_acc did not improve from 0.77165\n",
            "\n",
            "Epoch 00109: val_acc improved from 0.77165 to 0.77559, saving model to saved_weights/weights-improvement-109-0.78.hdf5\n",
            "\n",
            "Epoch 00110: val_acc did not improve from 0.77559\n",
            "\n",
            "Epoch 00111: val_acc did not improve from 0.77559\n",
            "\n",
            "Epoch 00112: val_acc did not improve from 0.77559\n",
            "\n",
            "Epoch 00113: val_acc did not improve from 0.77559\n",
            "\n",
            "Epoch 00114: val_acc did not improve from 0.77559\n",
            "\n",
            "Epoch 00115: val_acc did not improve from 0.77559\n",
            "\n",
            "Epoch 00116: val_acc did not improve from 0.77559\n",
            "\n",
            "Epoch 00117: val_acc did not improve from 0.77559\n",
            "\n",
            "Epoch 00118: val_acc improved from 0.77559 to 0.78740, saving model to saved_weights/weights-improvement-118-0.79.hdf5\n",
            "\n",
            "Epoch 00119: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00120: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00121: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00122: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00123: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00124: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00125: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00126: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00127: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00128: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00129: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00130: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00131: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00132: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00133: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00134: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00135: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00136: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00137: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00138: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00139: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00140: val_acc did not improve from 0.78740\n",
            "\n",
            "Epoch 00141: val_acc improved from 0.78740 to 0.79134, saving model to saved_weights/weights-improvement-141-0.79.hdf5\n",
            "\n",
            "Epoch 00142: val_acc did not improve from 0.79134\n",
            "\n",
            "Epoch 00143: val_acc did not improve from 0.79134\n",
            "\n",
            "Epoch 00144: val_acc did not improve from 0.79134\n",
            "\n",
            "Epoch 00145: val_acc did not improve from 0.79134\n",
            "\n",
            "Epoch 00146: val_acc did not improve from 0.79134\n",
            "\n",
            "Epoch 00147: val_acc did not improve from 0.79134\n",
            "\n",
            "Epoch 00148: val_acc did not improve from 0.79134\n",
            "\n",
            "Epoch 00149: val_acc did not improve from 0.79134\n",
            "\n",
            "Epoch 00150: val_acc did not improve from 0.79134\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1ea66b9240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}