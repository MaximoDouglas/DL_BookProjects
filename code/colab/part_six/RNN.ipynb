{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaximoDouglas/deep_learning/blob/master/code/colab/part_six/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "co4MgreoOh9A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Upload the .csv file\n",
        "breast-cancer-wisconsin.csv"
      ]
    },
    {
      "metadata": {
        "id": "V_j8CUcDIACp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qQo5zr_tBbYW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load and plot data"
      ]
    },
    {
      "metadata": {
        "id": "qCLKk8u9Bdcl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "dataset = pandas.read_csv('international-airline-passengers.csv', usecols=[1], \n",
        "                          engine='python', skipfooter=3)\n",
        "plt.plot(dataset)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9taVERz3D0V0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MLP on Airlines Dataset - adapted\n",
        "Train Score: 531.71 MSE (23.06 RMSE)\n",
        "\n",
        "Test Score: 2355.06 MSE (48.53 RMSE)"
      ]
    },
    {
      "metadata": {
        "id": "LEOCeG6TD34s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Multilayer Perceptron to Predict International Airline Passengers (t+1, given t)\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "\n",
        "# load the dataset\n",
        "dataframe = pandas.read_csv('international-airline-passengers.csv', usecols=[1],\n",
        "engine='python', skipfooter=3)\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "print(len(train), len(test))\n",
        "\n",
        "# reshape into X=t and Y=t+1\n",
        "look_back = 1\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "# create and fit Multilayer Perceptron model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=8, input_dim=look_back, activation='relu'))\n",
        "model.add(Dense(units=1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=200, batch_size=2, verbose=2)\n",
        "\n",
        "# Estimate model performance\n",
        "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
        "print('Train Score: %.2f MSE (%.2f RMSE)'% (trainScore, math.sqrt(trainScore)))\n",
        "testScore = model.evaluate(testX, testY, verbose=0)\n",
        "print('Test Score: %.2f MSE (%.2f RMSE)'% (testScore, math.sqrt(testScore)))\n",
        "\n",
        "# generate predictions for training\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = numpy.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "\n",
        "# plot baseline and predictions\n",
        "plt.plot(dataset)\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ly-ErRqVFGPo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MLP with Window Method on Airline predction problem\n",
        "Train Score: 606.19 MSE (24.62 RMSE)\n",
        "\n",
        "Test Score: 2613.03 MSE (51.12 RMSE)"
      ]
    },
    {
      "metadata": {
        "id": "UCOitNuOFLbs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Multilayer Perceptron to Predict International Airline Passengers (t+1, given t, t-1, t-2)\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load the dataset\n",
        "dataframe = pandas.read_csv('international-airline-passengers.csv', usecols=[1],\n",
        "engine='python', skipfooter=3)\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "print(len(train), len(test))\n",
        "\n",
        "# reshape dataset\n",
        "look_back = 10\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "# create and fit Multilayer Perceptron model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=8, input_dim=look_back, activation='relu'))\n",
        "model.add(Dense(units=1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=200, batch_size=2, verbose=2)\n",
        "\n",
        "# Estimate model performance\n",
        "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
        "print('Train Score: %.2f MSE (%.2f RMSE)'% (trainScore, math.sqrt(trainScore)))\n",
        "testScore = model.evaluate(testX, testY, verbose=0)\n",
        "print('Test Score: %.2f MSE (%.2f RMSE)'% (testScore, math.sqrt(testScore)))\n",
        "\n",
        "# generate predictions for training\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = numpy.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "\n",
        "# plot baseline and predictions\n",
        "plt.plot(dataset)\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JyArcQT3I_QL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM on airline data - adapted\n",
        "Train Score: 126.92 RMSE\n",
        "\n",
        "Test Score: 151.53 RMSE"
      ]
    },
    {
      "metadata": {
        "id": "jrUStbwsJB3g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LSTM for international airline passengers problem with regression framing\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "# fix random seed for reproducibility25.1. LSTM Network For Regression\n",
        "numpy.random.seed(7)\n",
        "\n",
        "# load the dataset\n",
        "dataframe = pandas.read_csv('international-airline-passengers.csv', usecols=[1],\n",
        "engine='python', skipfooter=3)\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "# reshape into X=t and Y=t+1\n",
        "look_back = 1\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "\n",
        "# create and fit the LSTM network\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=4, input_shape=(None, look_back)))\n",
        "model.add(Dense(units=1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
        "\n",
        "# Estimate model performance\n",
        "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
        "trainScore = math.sqrt(trainScore)\n",
        "trainScore = scaler.inverse_transform(numpy.array([[trainScore]]))\n",
        "print('Train Score: %.2f RMSE'% (trainScore))\n",
        "testScore = model.evaluate(testX, testY, verbose=0)\n",
        "testScore = math.sqrt(testScore)\n",
        "testScore = scaler.inverse_transform(numpy.array([[testScore]]))\n",
        "print('Test Score: %.2f RMSE'% (testScore))\n",
        "\n",
        "# generate predictions for training\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = numpy.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "\n",
        "# plot baseline and predictions\n",
        "plt.plot(dataset)\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GWlJ9sIbMIS5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM and Window Method on airline data - adapted\n",
        "Train Score: 128.19 RMSE\n",
        "\n",
        "Test Score: 162.05 RMSE"
      ]
    },
    {
      "metadata": {
        "id": "UgXQmGQYMTc1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LSTM for international airline passengers problem with window regression framing\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "\n",
        "# load the dataset\n",
        "dataframe = pandas.read_csv('international-airline-passengers.csv', usecols=[1],\n",
        "engine='python', skipfooter=3)\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "# reshape into X=t and Y=t+1\n",
        "look_back = 3\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "\n",
        "# create and fit the LSTM network\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, input_shape=(None, look_back)))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
        "\n",
        "# Estimate model performance\n",
        "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
        "trainScore = math.sqrt(trainScore)\n",
        "trainScore = scaler.inverse_transform(numpy.array([[trainScore]]))\n",
        "print('Train Score: %.2f RMSE'% (trainScore))\n",
        "testScore = model.evaluate(testX, testY, verbose=0)\n",
        "testScore = math.sqrt(testScore)\n",
        "testScore = scaler.inverse_transform(numpy.array([[testScore]]))\n",
        "print('Test Score: %.2f RMSE'% (testScore))\n",
        "\n",
        "# generate predictions for training\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = numpy.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "\n",
        "# plot baseline and predictions\n",
        "plt.plot(dataset)\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8KMnSY7yOmmP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM with timesteps Method on airline data - adapted\n",
        "Train Score: 127.70 RMSE\n",
        "\n",
        "Test Score: 162.77 RMSE"
      ]
    },
    {
      "metadata": {
        "id": "LPtEEz5uOux7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LSTM for international airline passengers problem with time step regression framing\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "\n",
        "# load the dataset\n",
        "dataframe = pandas.read_csv('international-airline-passengers.csv', usecols=[1],\n",
        "engine='python', skipfooter=3)\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "# reshape into X=t and Y=t+1\n",
        "look_back = 3\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
        "testX = numpy.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
        "\n",
        "# create and fit the LSTM network\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, input_shape=(look_back, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
        "\n",
        "# Estimate model performance\n",
        "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
        "trainScore = math.sqrt(trainScore)\n",
        "trainScore = scaler.inverse_transform(numpy.array([[trainScore]]))\n",
        "print('Train Score: %.2f RMSE'% (trainScore))\n",
        "testScore = model.evaluate(testX, testY, verbose=0)\n",
        "testScore = math.sqrt(testScore)\n",
        "testScore = scaler.inverse_transform(numpy.array([[testScore]]))\n",
        "print('Test Score: %.2f RMSE'% (testScore))\n",
        "\n",
        "# generate predictions for training\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = numpy.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "\n",
        "# plot baseline and predictions\n",
        "plt.plot(dataset)\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}