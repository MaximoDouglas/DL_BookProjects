{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaximoDouglas/deep_learning/blob/master/code/colab/part_six/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "co4MgreoOh9A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Upload the .csv file\n",
        "breast-cancer-wisconsin.csv"
      ]
    },
    {
      "metadata": {
        "id": "V_j8CUcDIACp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qQo5zr_tBbYW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load and plot data"
      ]
    },
    {
      "metadata": {
        "id": "qCLKk8u9Bdcl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "dataset = pandas.read_csv('international-airline-passengers.csv', usecols=[1], \n",
        "                          engine='python', skipfooter=3)\n",
        "plt.plot(dataset)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9taVERz3D0V0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MLP on Airlines Dataset - adapted\n",
        "Train Score: 531.71 MSE (23.06 RMSE)\n",
        "\n",
        "Test Score: 2355.06 MSE (48.53 RMSE)"
      ]
    },
    {
      "metadata": {
        "id": "LEOCeG6TD34s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Multilayer Perceptron to Predict International Airline Passengers (t+1, given t)\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "\n",
        "# load the dataset\n",
        "dataframe = pandas.read_csv('international-airline-passengers.csv', usecols=[1],\n",
        "engine='python', skipfooter=3)\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "print(len(train), len(test))\n",
        "\n",
        "# reshape into X=t and Y=t+1\n",
        "look_back = 1\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "# create and fit Multilayer Perceptron model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=8, input_dim=look_back, activation='relu'))\n",
        "model.add(Dense(units=1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=200, batch_size=2, verbose=2)\n",
        "\n",
        "# Estimate model performance\n",
        "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
        "print('Train Score: %.2f MSE (%.2f RMSE)'% (trainScore, math.sqrt(trainScore)))\n",
        "testScore = model.evaluate(testX, testY, verbose=0)\n",
        "print('Test Score: %.2f MSE (%.2f RMSE)'% (testScore, math.sqrt(testScore)))\n",
        "\n",
        "# generate predictions for training\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = numpy.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "\n",
        "# plot baseline and predictions\n",
        "plt.plot(dataset)\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ly-ErRqVFGPo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MLP with Window Method on Airline predction problem\n",
        "Train Score: 606.19 MSE (24.62 RMSE)\n",
        "\n",
        "Test Score: 2613.03 MSE (51.12 RMSE)"
      ]
    },
    {
      "metadata": {
        "id": "UCOitNuOFLbs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Multilayer Perceptron to Predict International Airline Passengers (t+1, given t, t-1, t-2)\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load the dataset\n",
        "dataframe = pandas.read_csv('international-airline-passengers.csv', usecols=[1],\n",
        "engine='python', skipfooter=3)\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "print(len(train), len(test))\n",
        "\n",
        "# reshape dataset\n",
        "look_back = 10\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "# create and fit Multilayer Perceptron model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=8, input_dim=look_back, activation='relu'))\n",
        "model.add(Dense(units=1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=200, batch_size=2, verbose=2)\n",
        "\n",
        "# Estimate model performance\n",
        "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
        "print('Train Score: %.2f MSE (%.2f RMSE)'% (trainScore, math.sqrt(trainScore)))\n",
        "testScore = model.evaluate(testX, testY, verbose=0)\n",
        "print('Test Score: %.2f MSE (%.2f RMSE)'% (testScore, math.sqrt(testScore)))\n",
        "\n",
        "# generate predictions for training\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = numpy.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "\n",
        "# plot baseline and predictions\n",
        "plt.plot(dataset)\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JyArcQT3I_QL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM on airline data - adapted\n",
        "Train Score: 126.92 RMSE\n",
        "\n",
        "Test Score: 151.53 RMSE"
      ]
    },
    {
      "metadata": {
        "id": "jrUStbwsJB3g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LSTM for international airline passengers problem with regression framing\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "# fix random seed for reproducibility25.1. LSTM Network For Regression\n",
        "numpy.random.seed(7)\n",
        "\n",
        "# load the dataset\n",
        "dataframe = pandas.read_csv('international-airline-passengers.csv', usecols=[1],\n",
        "engine='python', skipfooter=3)\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "# reshape into X=t and Y=t+1\n",
        "look_back = 1\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "\n",
        "# create and fit the LSTM network\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=4, input_shape=(None, look_back)))\n",
        "model.add(Dense(units=1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
        "\n",
        "# Estimate model performance\n",
        "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
        "trainScore = math.sqrt(trainScore)\n",
        "trainScore = scaler.inverse_transform(numpy.array([[trainScore]]))\n",
        "print('Train Score: %.2f RMSE'% (trainScore))\n",
        "testScore = model.evaluate(testX, testY, verbose=0)\n",
        "testScore = math.sqrt(testScore)\n",
        "testScore = scaler.inverse_transform(numpy.array([[testScore]]))\n",
        "print('Test Score: %.2f RMSE'% (testScore))\n",
        "\n",
        "# generate predictions for training\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = numpy.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "\n",
        "# plot baseline and predictions\n",
        "plt.plot(dataset)\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GWlJ9sIbMIS5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM and Window Method on airline data - adapted\n",
        "Train Score: 128.19 RMSE\n",
        "\n",
        "Test Score: 162.05 RMSE"
      ]
    },
    {
      "metadata": {
        "id": "UgXQmGQYMTc1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LSTM for international airline passengers problem with window regression framing\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "\n",
        "# load the dataset\n",
        "dataframe = pandas.read_csv('international-airline-passengers.csv', usecols=[1],\n",
        "engine='python', skipfooter=3)\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "# reshape into X=t and Y=t+1\n",
        "look_back = 3\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "\n",
        "# create and fit the LSTM network\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, input_shape=(None, look_back)))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
        "\n",
        "# Estimate model performance\n",
        "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
        "trainScore = math.sqrt(trainScore)\n",
        "trainScore = scaler.inverse_transform(numpy.array([[trainScore]]))\n",
        "print('Train Score: %.2f RMSE'% (trainScore))\n",
        "testScore = model.evaluate(testX, testY, verbose=0)\n",
        "testScore = math.sqrt(testScore)\n",
        "testScore = scaler.inverse_transform(numpy.array([[testScore]]))\n",
        "print('Test Score: %.2f RMSE'% (testScore))\n",
        "\n",
        "# generate predictions for training\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = numpy.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "\n",
        "# plot baseline and predictions\n",
        "plt.plot(dataset)\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8KMnSY7yOmmP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM with timesteps Method on airline data - adapted\n",
        "Train Score: 127.70 RMSE\n",
        "\n",
        "Test Score: 162.77 RMSE"
      ]
    },
    {
      "metadata": {
        "id": "LPtEEz5uOux7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LSTM for international airline passengers problem with time step regression framing\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "\n",
        "# load the dataset\n",
        "dataframe = pandas.read_csv('international-airline-passengers.csv', usecols=[1],\n",
        "engine='python', skipfooter=3)\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "# reshape into X=t and Y=t+1\n",
        "look_back = 3\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
        "testX = numpy.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
        "\n",
        "# create and fit the LSTM network\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, input_shape=(look_back, 1)))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
        "\n",
        "# Estimate model performance\n",
        "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
        "trainScore = math.sqrt(trainScore)\n",
        "trainScore = scaler.inverse_transform(numpy.array([[trainScore]]))\n",
        "print('Train Score: %.2f RMSE'% (trainScore))\n",
        "testScore = model.evaluate(testX, testY, verbose=0)\n",
        "testScore = math.sqrt(testScore)\n",
        "testScore = scaler.inverse_transform(numpy.array([[testScore]]))\n",
        "print('Test Score: %.2f RMSE'% (testScore))\n",
        "\n",
        "# generate predictions for training\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = numpy.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "\n",
        "# plot baseline and predictions\n",
        "plt.plot(dataset)\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w4maX8GkSN6o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM with memory (stateful) on airline data - adapted\n",
        "Train Score: 124.80 RMSE\n",
        "\n",
        "Test Score: 159.35 RMSE"
      ]
    },
    {
      "metadata": {
        "id": "9CW4HLpDSQFx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LSTM for international airline passengers problem with memory\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "\n",
        "# load the dataset\n",
        "dataframe = pandas.read_csv('international-airline-passengers.csv', usecols=[1],\n",
        "engine='python', skipfooter=3)\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "# reshape into X=t and Y=t+1\n",
        "look_back = 3\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
        "testX = numpy.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
        "\n",
        "# create and fit the LSTM network\n",
        "batch_size = 1\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "for i in range(100):\n",
        "    model.fit(trainX, trainY, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n",
        "    model.reset_states()\n",
        "\n",
        "# Estimate model performance\n",
        "trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n",
        "model.reset_states()\n",
        "trainScore = math.sqrt(trainScore)\n",
        "trainScore = scaler.inverse_transform(numpy.array([[trainScore]]))\n",
        "print('Train Score: %.2f RMSE'% (trainScore))\n",
        "testScore = model.evaluate(testX, testY, batch_size=batch_size, verbose=0)\n",
        "model.reset_states()\n",
        "testScore = math.sqrt(testScore)\n",
        "testScore = scaler.inverse_transform(numpy.array([[testScore]]))\n",
        "print('Test Score: %.2f RMSE'% (testScore))\n",
        "\n",
        "# generate predictions for training\n",
        "trainPredict = model.predict(trainX, batch_size=batch_size)\n",
        "testPredict = model.predict(testX, batch_size=batch_size)\n",
        "\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = numpy.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "\n",
        "# plot baseline and predictions\n",
        "plt.plot(dataset)\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9vUVsCmHU_dT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM with stacked LSTM layers - adapted\n",
        "Train Score: 133.84 RMSE\n",
        "\n",
        "Test Score: 183.52 RMSE\n"
      ]
    },
    {
      "metadata": {
        "id": "s0HpJg3UVH1x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Stacked LSTM for international airline passengers problem with memory\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return numpy.array(dataX), numpy.array(dataY)\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "\n",
        "# load the dataset\n",
        "dataframe = pandas.read_csv('../data/international-airline-passengers.csv', usecols=[1],\n",
        "engine='python', skipfooter=3)\n",
        "dataset = dataframe.values\n",
        "dataset = dataset.astype('float32')\n",
        "\n",
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "# reshape into X=t and Y=t+1\n",
        "look_back = 3\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
        "testX = numpy.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
        "\n",
        "# create and fit the LSTM network\n",
        "batch_size = 1\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True,\n",
        "return_sequences=True))\n",
        "model.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "for i in range(100):\n",
        "    model.fit(trainX, trainY, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n",
        "    model.reset_states()\n",
        "\n",
        "# Estimate model performance\n",
        "trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n",
        "model.reset_states()\n",
        "trainScore = math.sqrt(trainScore)\n",
        "trainScore = scaler.inverse_transform(numpy.array([[trainScore]]))\n",
        "print('Train Score: %.2f RMSE'% (trainScore))\n",
        "testScore = model.evaluate(testX, testY, batch_size=batch_size, verbose=0)\n",
        "model.reset_states()\n",
        "testScore = math.sqrt(testScore)\n",
        "testScore = scaler.inverse_transform(numpy.array([[testScore]]))\n",
        "print('Test Score: %.2f RMSE'% (testScore))\n",
        "\n",
        "# generate predictions for training\n",
        "trainPredict = model.predict(trainX, batch_size=batch_size)\n",
        "model.reset_states()\n",
        "testPredict = model.predict(testX, batch_size=batch_size)\n",
        "model.reset_states()\n",
        "\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = numpy.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = numpy.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(dataset)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "\n",
        "# plot baseline and predictions\n",
        "plt.plot(dataset)\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "McpHBNGAYZaN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM on IMDB data - adapted\n",
        "Accuracy: 86.28%"
      ]
    },
    {
      "metadata": {
        "id": "E1k5AiPoYhGp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LSTM for sequence classification in the IMDB dataset\n",
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from theano.tensor.shared_randomstreams import RandomStreams\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "srng = RandomStreams(7)\n",
        "\n",
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "test_split = 0.33\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "# truncate and pad input sequences\n",
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
        "\n",
        "# create the model\n",
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iWEueqv5aMoI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM on IMDB data with dropout - adapted"
      ]
    },
    {
      "metadata": {
        "id": "4MFV6fYFaVgq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LSTM with Dropout for sequence classification in the IMDB dataset\n",
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from theano.tensor.shared_randomstreams import RandomStreams\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "srng = RandomStreams(7)\n",
        "\n",
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "test_split = 0.33\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "# truncate and pad input sequences\n",
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
        "\n",
        "# create the model\n",
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length, dropout=0.2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train, y_train, nb_epoch=3, batch_size=64)\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BgDiV36gcZ0S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LSTM with recurrent dropout - adapted"
      ]
    },
    {
      "metadata": {
        "id": "feQiZl4Rce-E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LSTM with dropout for sequence classification in the IMDB dataset\n",
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from theano.tensor.shared_randomstreams import RandomStreams\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "srng = RandomStreams(7)\n",
        "\n",
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "test_split = 0.33\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "# truncate and pad input sequences\n",
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
        "\n",
        "# create the model\n",
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100, dropout_W=0.2, dropout_U=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}